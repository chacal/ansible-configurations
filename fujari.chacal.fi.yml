---
#
# This playbook is used to provision Fujari after fresh Proxmox installation
# Assumptions:
#  - Passwordless SSH connection with "root"
#

- hosts: all
  remote_user: root
  gather_facts: yes

  vars_files:
    - secrets.yml

  vars:
    arc_cache_size: 3221225472
    disks:
      - /dev/disk/by-id/scsi-36003005701ef594025e3130b929326b3  # /dev/sdc, 1.8TB HDD
      - /dev/disk/by-id/scsi-36003005701ef594025e3130b9293bb07  # /dev/sdc, 1.8TB HDD

  handlers:
    - name: Update boot parameters
      command: pve-efiboot-tool refresh
    - name: Update ARC cache size
      shell: |
        echo {{ arc_cache_size }} > /sys/module/zfs/parameters/zfs_arc_max
        echo 3 > /proc/sys/vm/drop_caches

  roles:

  tasks:

    - name: Check log compression
      shell: grep -rE '(^|[^#y])compress' /etc/logrotate.d
      register: log_compression
      changed_when: False
      failed_when: log_compression.rc > 1

    - name: Disable log compression (zfs already compresses them)
      shell: |
        for file in /etc/logrotate.d/* ; do
            if grep -Eq "(^|[^#y])compress" "$file" ; then
                sed -i -r "s/(^|[^#y])(compress)/\1#\2/" "$file"
            fi
        done
      when: log_compression.rc == 0

    - name: Enable IOMMU
      copy:
        dest: /etc/kernel/cmdline
        content: root=ZFS=rpool/ROOT/pve-1 boot=zfs intel_iommu=on
      notify: Update boot parameters

    - name: Load required modules for IOMMU
      lineinfile:
        dest: /etc/modules
        state: present
        line: '{{ item }}'
      loop:
        - vfio
        - vfio_iommu_type1
        - vfio_pci
        - vfio_virqfd

    - name: Cap ZFS ARC cache
      copy:
        dest: /etc/modprobe.d/zfs.conf
        content: 'options zfs zfs_arc_max={{ arc_cache_size }}'
      notify: Update ARC cache size

    - name: Create directory for cloud-init userdata files
      file:
        path: /var/lib/vz/snippets
        state: directory

    - name: Remove PVE Enterprise APT repository
      file:
        path: /etc/apt/sources.list.d/pve-enterprise.list
        state: absent

    - name: Add PVE no-subscription APT repository
      apt_repository:
        repo: deb http://download.proxmox.com/debian/pve buster pve-no-subscription
        state: present

    # Stop storage replication systemd timer to prevent it from polluting logs
    - name: Stop PVE storage replication timer
      systemd:
        name: "pvesr.timer"
        daemon_reload: yes
        enabled: no
        state: stopped



    ######################################################
    #
    #  Setup ZFS hddpool and PVE storage pool in it
    #
    - name: Gather zpool facts
      zpool_facts:
      tags: storagepools

    - set_fact:
        hddpool_missing: "{{ 'hddpool' not in ansible_zfs_pools | map(attribute='name') }}"
      tags: storagepools

    - name: Confirm hddpool creation
      pause:
        prompt: |

          ##################################################################################
          ##
          ##  WARNING!! WARNING!! WARNING!! WARNING!!
          ##
          ##  ZFS pool "hddpool" doesn't exist!
          ##
          ##  Do you want to create it? This will WIPE ALL DATA on /dev/sdc and /dev/sdd!
          ##
          ##  Create hddpool? (yes/no) (Answering "no" skips the pool creation)
      register: create_hddpool
      when: hddpool_missing | bool
      tags: storagepools

    - name: Create ZFS pool "hddpool"
      block:
        - name: Remove existing partitions
          shell: |
            sgdisk --zap-all {{ item }}
          loop: "{{ vars.disks }}"
        - name: Remove potentially existing ZFS labels
          shell: |
            zpool labelclear -f {{ item }}
            sleep 2
          loop: "{{ vars.disks }}"
          ignore_errors: yes
        - name: Create hddpool pool
          shell: |
            zpool create -o ashift=12 \
                -O acltype=posixacl -O canmount=off -O compression=lz4 \
                -O dnodesize=auto -O normalization=formD -O relatime=on -O xattr=sa \
                hddpool \
                mirror {{ vars.disks | join(' ') }}
      when: hddpool_missing and create_hddpool.user_input | default(false) | bool
      tags: storagepools

    - name: Gather zfs mounts
      command: zfs mount
      register: zfs_mounts
      changed_when: False
      tags: storagepools

    - name: Create datasets
      zfs:
        name: "{{ item.name }}"
        extra_zfs_properties:
          canmount: "{{ item.canmount }}"
          mountpoint: "{{ item.mountpoint }}"
        state: present
      when: "zfs_mounts.stdout_lines | select('search', item.name) | list | count == 0"
      loop:
        - { name: hddpool/nonbackupped, mountpoint: /hddpool/nonbackupped, canmount: on }
        - { name: rpool/nonbackupped, mountpoint: /rpool/nonbackupped, canmount: on }
      tags: storagepools

    - name: Gather storage pools
      shell: pvesm status | sed "1d" | awk '{print $1}'
      register: storage_pools
      changed_when: False
      tags: storagepools

    - name: Create PVE storage pools
      command:
        cmd: "pvesm add zfspool {{ item.name }} --pool {{ item.dataset }} --content rootdir,images --sparse 1"
      when: "item.name not in storage_pools.stdout_lines"
      loop:
        - { name: "hdd-zfs-nonbackupped", dataset: hddpool/nonbackupped }
        - { name: "local-zfs-nonbackupped", dataset: rpool/nonbackupped }
      tags: storagepools
